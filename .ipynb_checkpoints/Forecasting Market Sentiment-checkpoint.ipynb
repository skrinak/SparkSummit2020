{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Future of Market Sentiment\n",
    "\n",
    "Using classical technical analysis which tends to focus on the market sentiment \n",
    "of the moment we apply modern deep learning to see the near-term future and attempt\n",
    "avoid misfires.\n",
    "\n",
    "Our algorithm of choice, DeepAR, enables forecasting on very large datasets composed of multiple \n",
    "timeseries. This is a typical investment portfolio. Unlike other forecasting algorithms such as \n",
    "EMS, Prophet, and ARIMA, DeepAR uses a deep learning encoder/decoder model to discover behavioral\n",
    "relationships in the data that are otherwise inaccessible. We expect this model to yeild non-intuitive \n",
    "results that are specifically relevant to the instruments in our basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add symbols to your portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = ('AMZN', 'GOOG', 'FB', 'AAPL', 'SPY', 'TSLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = 'sparkSummitDemo'\n",
    "\n",
    "# Training data range. Choose a minimum 2-year timeframe that best matches current conditions. \n",
    "start_date = '2014-01-01'\n",
    "end_date = '2016-01-01'\n",
    "\n",
    "s3_bucket = '2021-demos'\n",
    "s3_prefix = 'sparkSummit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get historical data\n",
    "\n",
    "Any timeframe can be used to train data. We're living in a time of economic collapes, \n",
    "not the first. Recent periods such as the 2008 recession might be a good choice. Ensure that \n",
    "the instruments in your portfolio existed at the time period of your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prices for each symbol in time range\n",
    "portfolio_history = []\n",
    "for ticker in portfolio: \n",
    "    portfolio_history.append(web.DataReader(ticker, data_source = 'yahoo', start=start_date, end=end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add indicators to price action history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential moving averages: 13- and 50-day\n",
    "\n",
    "EMAs are persistent. We'll need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in portfolio_history:\n",
    "    ticker['EMA13'] = ticker.Close.ewm(span=13).mean()\n",
    "    ticker['EMA50'] = ticker.Close.ewm(span=50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACD - Moving Average Convergence/Divergence\n",
    "\n",
    "MACD measures trend health. EMAs calculated in MACD are ephemeral. We can toss them once we've calculated the MACD histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ticker in enumerate(portfolio_history):\n",
    "    EMA12 = ticker.Close.ewm(span=12, adjust=False).mean()\n",
    "    EMA26 = ticker.Close.ewm(span=26, adjust=False).mean()\n",
    "    MACD = EMA12-EMA26\n",
    "    signal = MACD.ewm(span=9, adjust=False).mean()\n",
    "    portfolio_history[i]['MACDhistogram'] = MACD - signal\n",
    "    del EMA12, EMA26, MACD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow Stochastics\n",
    "\n",
    "The poorly-named yet highly-effective \"Slow Stochastics\" is a trigger indicator. An upward cross in the lower 20% is bullish, a downward cross in the upper 10% is bearish.  Again, All we care about is the fast and slow line. Ephemeral values are tossed aside. \n",
    "\n",
    "```\n",
    "%K = (Current Close - Lowest Low)/(Highest High - Lowest Low) * 100\n",
    "%D = 3-day SMA of %K\n",
    "```\n",
    "\n",
    "* %K is generally called the \"slow line\", and %D the \"fast line\"\n",
    "* Lowest Low = lowest low for the look-back period\n",
    "* Highest High = highest high for the look-back period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ticker in enumerate(portfolio_history):\n",
    "    rollingLow, rollingHigh = ticker.Low.rolling(14).min(), ticker.High.rolling(14).max()\n",
    "    fastLine = 100 * (ticker.Close - rollingLow) / (rollingHigh - rollingLow) \n",
    "    slowLine = fastLine.rolling(3).mean()\n",
    "    portfolio_history[i]['fast_stoch'] = fastLine\n",
    "    portfolio_history[i]['slow_stoch'] = slowLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_history[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the last 50 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 50\n",
    "\n",
    "emaCross = portfolio_history[0][['Close', 'EMA13', 'EMA50']].tail(days)\n",
    "emaCross.plot(figsize=(20,10))\n",
    "\n",
    "slowStochastic = portfolio_history[0][:days][['slow_stoch', 'fast_stoch']].tail(days)\n",
    "MACDhistogram = portfolio_history[0][['MACDhistogram']].tail(days)\n",
    "\n",
    "MACDhistogram.plot(figsize=(20,2), kind='bar', xticks=[])\n",
    "slowStochastic.plot(figsize=(20,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the Training and Test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the entire dataset for training. We need to forcast 5 different indicators: \n",
    "\n",
    "* The 13-day EMA\n",
    "* The 50-day EMA\n",
    "* The MACD Histogram, and\n",
    "* Both Slow Stochastics indicators\n",
    "\n",
    "We'll align them on parallel paths as single factor targets. Data will align on the timestamp index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = str(portfolio_history[0].index[0])\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_EMA13 = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.EMA13.tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "train_EMA50 = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.EMA50.tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "train_MACDhistogram = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.MACDhistogram.tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "\n",
    "fast_stoch_target = ticker.fast_stoch.dropna()\n",
    "train_fast_stoch = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": fast_stoch_target.tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "\n",
    "slow_stoch_target = ticker.slow_stoch.dropna()\n",
    "train_slow_stoch = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": slow_stoch_target.tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test set we'll use the last 50 values of each indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = 50\n",
    "\n",
    "test_EMA13 = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.EMA13.tail(periods).tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "test_EMA50 = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.EMA50.tail(periods).tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "test_MACDhistogram = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.MACDhistogram.tail(periods).tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "test_fast_stoch = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.fast_stoch.tail(periods).tolist()\n",
    "    } for ticker in portfolio_history\n",
    "]\n",
    "test_slow_stoch = [\n",
    "    {\n",
    "        \"start\": start_date,\n",
    "        \"target\": ticker.slow_stoch.tail(periods).tolist() \n",
    "    } for ticker in portfolio_history\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are prepared. Ship them up to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "write_dicts_to_file(\"train_EMA13.json\", train_EMA13)\n",
    "write_dicts_to_file(\"test_EMA13.json\", test_EMA13)\n",
    "\n",
    "write_dicts_to_file(\"train_EMA50.json\", train_EMA50)\n",
    "write_dicts_to_file(\"test_EMA50.json\", test_EMA50)\n",
    "\n",
    "write_dicts_to_file(\"train_MACDhistogram.json\", train_MACDhistogram)\n",
    "write_dicts_to_file(\"test_MACDhistogram.json\", test_MACDhistogram)\n",
    "\n",
    "write_dicts_to_file(\"train_fast_stoch.json\", train_fast_stoch)\n",
    "write_dicts_to_file(\"test_fast_stoch.json\", test_fast_stoch)\n",
    "\n",
    "write_dicts_to_file(\"train_slow_stoch.json\", train_slow_stoch)\n",
    "write_dicts_to_file(\"test_slow_stoch.json\", test_slow_stoch)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "for dataset in ['EMA13', 'EMA50', 'MACDhistogram', 'fast_stoch', 'slow_stoch']:\n",
    "    filename = 'train_' + dataset + '.json'\n",
    "    with open(filename, 'rb') as data:\n",
    "        key = s3_prefix + '/data/' + dataset + '/' + filename\n",
    "        result = bucket.put_object(Key=key, Body=data)\n",
    "        print('Uploaded file to {}'.format(result))\n",
    "\n",
    "    filename = 'test_' + dataset + '.json'\n",
    "    with open(filename, 'rb') as data:\n",
    "        key = s3_prefix + '/data/' + dataset + '/' + filename\n",
    "        result = bucket.put_object(Key=key, Body=data)\n",
    "        print('Uploaded file to {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DeepAR in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_JSON\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = os.getenv('SAGEMAKER_ROLE')\n",
    "region = sagemaker_session.boto_region_name\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing data parameters\n",
    "\n",
    "Set the hyperparameters for reuse on every indicator. In the real world we'd create a utility routine to do this. As this is a demo we're explicitly building each predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'D'\n",
    "context_length = prediction_length = 14\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"20\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_EMA13 = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name + '-EMA13',\n",
    "    output_path=\"s3://{}/{}/output/EMA13/train_EMA13.json\".format(s3_bucket, s3_prefix)\n",
    ")\n",
    "estimator_EMA13.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/{}/data/EMA13/train_EMA13.json\".format(s3_bucket, s3_prefix),\n",
    "    \"test\":  \"s3://{}/{}/data/EMA13/test_EMA13.json\".format(s3_bucket, s3_prefix)\n",
    "}\n",
    "\n",
    "estimator_EMA13.fit(inputs=data_channels, wait=False)\n",
    "\n",
    "estimator_EMA50 = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name + '-EMA50',\n",
    "    output_path=\"s3://{}/{}/output/EMA50/train_EMA50.json\".format(s3_bucket, s3_prefix)\n",
    ")\n",
    "estimator_EMA50.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/{}/data/EMA50/train_EMA50.json\".format(s3_bucket, s3_prefix),\n",
    "    \"test\":  \"s3://{}/{}/data/EMA50/test_EMA50.json\".format(s3_bucket, s3_prefix)\n",
    "}\n",
    "\n",
    "estimator_EMA50.fit(inputs=data_channels, wait=False)\n",
    "\n",
    "estimator_MACDhistogram = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name + '-MACD',\n",
    "    output_path=\"s3://{}/{}/output/MACDhistogram/train_MACDhistogram.json\".format(s3_bucket, s3_prefix)\n",
    ")\n",
    "estimator_MACDhistogram.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/{}/data/MACDhistogram/train_MACDhistogram.json\".format(s3_bucket, s3_prefix),\n",
    "    \"test\":  \"s3://{}/{}/data/MACDhistogram/test_MACDhistogram.json\".format(s3_bucket, s3_prefix)\n",
    "}\n",
    "\n",
    "estimator_MACDhistogram.fit(inputs=data_channels, wait=False)\n",
    "\n",
    "estimator_fast_stoch = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name + '-fast-stoch',\n",
    "    output_path=\"s3://{}/{}/output/fast_stoch/train_fast_stoch.json\".format(s3_bucket, s3_prefix)\n",
    ")\n",
    "estimator_fast_stoch.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/{}/data/fast_stoch/train_fast_stoch.json\".format(s3_bucket, s3_prefix),\n",
    "    \"test\":  \"s3://{}/{}/data/fast_stoch/test_fast_stoch.json\".format(s3_bucket, s3_prefix)\n",
    "}\n",
    "\n",
    "estimator_fast_stoch.fit(inputs=data_channels, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait on this oneâ€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_slow_stoch = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name + '-slow-stoch',\n",
    "    output_path=\"s3://{}/{}/output/slow_stoch/train_slow_stoch.json\".format(s3_bucket, s3_prefix)\n",
    ")\n",
    "estimator_slow_stoch.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/{}/data/slow_stoch/train_slow_stoch.json\".format(s3_bucket, s3_prefix),\n",
    "    \"test\":  \"s3://{}/{}/data/slow_stoch/test_slow_stoch.json\".format(s3_bucket, s3_prefix)\n",
    "}\n",
    "\n",
    "estimator_slow_stoch.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_EMA13 = estimator_EMA13.deploy(\n",
    "    wait=False,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')\n",
    "\n",
    "predictor_EMA50 = estimator_EMA50.deploy(\n",
    "    wait=False,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')\n",
    "\n",
    "predictor_MACDhistogram = estimator_MACDhistogram.deploy(\n",
    "    wait=False,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')\n",
    "\n",
    "predictor_fast_stoch = estimator_fast_stoch.deploy(\n",
    "    wait=False,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')\n",
    "\n",
    "predictor_slow_stoch = estimator_slow_stoch.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inference request from holdout set\n",
    "\n",
    "For prediction we only care about the next 14 days. And, we want a prediction based on current market action. This dataset just like the training set can be tuned. For the demo we're getting the last 70 days. That's just enough to get a full indicator set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import BDay\n",
    "holdout_start = (datetime.now() - BDay(70)).strftime(\"%Y-%m-%d\")\n",
    "holdout_end = (datetime.now() - BDay(1)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_set = []\n",
    "for ticker in portfolio: \n",
    "    holdout_set.append(web.DataReader(ticker, data_source = 'yahoo', start=holdout_start, end=holdout_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create indicators for the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in holdout_set:\n",
    "    ticker['EMA13'] = ticker.Close.ewm(span=13).mean()\n",
    "    ticker['EMA50'] = ticker.Close.ewm(span=50).mean()\n",
    "\n",
    "for i, ticker in enumerate(holdout_set):\n",
    "    EMA12 = ticker.Close.ewm(span=12, adjust=False).mean()\n",
    "    EMA26 = ticker.Close.ewm(span=26, adjust=False).mean()\n",
    "    MACD = EMA12-EMA26\n",
    "    signal = MACD.ewm(span=9, adjust=False).mean()\n",
    "    holdout_set[i]['MACDhistogram'] = MACD - signal\n",
    "    del EMA12, EMA26, MACD\n",
    "\n",
    "for i, ticker in enumerate(holdout_set):\n",
    "    rollingLow, rollingHigh = ticker.Low.rolling(14).min(), ticker.High.rolling(14).max()\n",
    "    fastLine = 100 * (ticker.Close - rollingLow) / (rollingHigh - rollingLow) \n",
    "    slowLine = fastLine.rolling(3).mean()\n",
    "    holdout_set[i]['fast_stoch'] = fastLine\n",
    "    holdout_set[i]['slow_stoch'] = slowLine\n",
    "\n",
    "holdout_set[0][-14:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"start\": holdout_start,\n",
    "            \"target\": holdout_set[0].EMA13.tolist()\n",
    "        }\n",
    "    ],\n",
    "    \"configuration\": {\n",
    "         \"num_samples\": holdout_set[0].shape[0],\n",
    "         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "         \"quantiles\": [\"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "infer = RealTimePredictor( endpoint=predictor_EMA13.endpoint, \n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                serializer=json_serializer,\n",
    "                                content_type=CONTENT_TYPE_JSON)\n",
    "result = infer.predict(request)\n",
    "predictions = json.loads(result.decode('utf-8'))['predictions'][0]\n",
    "preds_EMA13 = pd.DataFrame(predictions['quantiles']['0.5'])\n",
    "del request, infer, predictions\n",
    "\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"start\": holdout_start,\n",
    "            \"target\": holdout_set[0].EMA50.tolist()\n",
    "        }\n",
    "    ],\n",
    "    \"configuration\": {\n",
    "         \"num_samples\": holdout_set[0].shape[0],\n",
    "         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "         \"quantiles\": [\"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "infer = RealTimePredictor( endpoint=predictor_EMA50.endpoint, \n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                serializer=json_serializer,\n",
    "                                content_type=CONTENT_TYPE_JSON)\n",
    "result = infer.predict(request)\n",
    "predictions = json.loads(result.decode('utf-8'))['predictions'][0]\n",
    "preds_EMA50 = pd.DataFrame(predictions['quantiles']['0.5'])\n",
    "del request, infer, predictions\n",
    "\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"start\": holdout_start,\n",
    "            \"target\": holdout_set[0].MACDhistogram.tolist()\n",
    "        }\n",
    "    ],\n",
    "    \"configuration\": {\n",
    "         \"num_samples\": holdout_set[0].shape[0],\n",
    "         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "         \"quantiles\": [\"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "infer = RealTimePredictor( endpoint=predictor_MACDhistogram.endpoint, \n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                serializer=json_serializer,\n",
    "                                content_type=CONTENT_TYPE_JSON)\n",
    "result = infer.predict(request)\n",
    "predictions = json.loads(result.decode('utf-8'))['predictions'][0]\n",
    "preds_MACDhistogram = pd.DataFrame(predictions['quantiles']['0.5'])\n",
    "del request, infer, predictions\n",
    "\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"start\": holdout_start,\n",
    "            \"target\": holdout_set[0].fast_stoch.tolist()\n",
    "        }\n",
    "    ],\n",
    "    \"configuration\": {\n",
    "         \"num_samples\": holdout_set[0].shape[0],\n",
    "         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "         \"quantiles\": [\"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "infer = RealTimePredictor( endpoint=predictor_fast_stoch.endpoint, \n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                serializer=json_serializer,\n",
    "                                content_type=CONTENT_TYPE_JSON)\n",
    "result = infer.predict(request)\n",
    "predictions = json.loads(result.decode('utf-8'))['predictions'][0]\n",
    "preds_fast_stoch = pd.DataFrame(predictions['quantiles']['0.5'])\n",
    "del request, infer, predictions\n",
    "\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"start\": holdout_start,\n",
    "            \"target\": holdout_set[0].slow_stoch.tolist()\n",
    "        }\n",
    "    ],\n",
    "    \"configuration\": {\n",
    "         \"num_samples\": holdout_set[0].shape[0],\n",
    "         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "         \"quantiles\": [\"0.5\", \"0.9\"]\n",
    "    }\n",
    "}\n",
    "infer = RealTimePredictor( endpoint=predictor_slow_stoch.endpoint, \n",
    "                                sagemaker_session=sagemaker_session, \n",
    "                                serializer=json_serializer,\n",
    "                                content_type=CONTENT_TYPE_JSON)\n",
    "result = infer.predict(request)\n",
    "predictions = json.loads(result.decode('utf-8'))['predictions'][0]\n",
    "preds_slow_stoch = pd.DataFrame(predictions['quantiles']['0.5'])\n",
    "del request, infer, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preds_EMA13)\n",
    "# print(preds_EMA50)\n",
    "# print(holdout_set[0][-15:-1])\n",
    "# print(preds_slow_stoch)\n",
    "# print(preds_fast_stoch)\n",
    "# print(preds_MACDhistogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_MACDhistogram.plot(figsize=(20,5), kind='bar')\n",
    "# pd.plot(preds_fast_stoch, preds_slow_stoch)\n",
    "# pd.plot(preds_MACDhistogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_EMA13.plot(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
